server:
  port: 8090
  servlet:
    # 配置项目名称（默认为 /），如果配置了项目名称，那么在访问路径中要加上配置的路径
    context-path: /
    session:
      # 服务器session最大超时时间(分钟)
      timeout: 30m
    encoding:
      charset: UTF-8
  # tomcat配置
  tomcat:
    # tomcat 基础路径
    basedir: ./
    # tomcat字符集
    uri-encoding: UTF-8
    # tomcat最大连接数
    max-connections: 2000
    # accept队列长度
    accept-count: 5000
    # 最大连接超时时间，单位：毫秒
    connection-timeout: 5000
    threads:
      # tomcat最大线程数
      max: 1000
    accesslog:
      # 启用访问日志
      enabled: true
      # 访问日志的格式模式
      pattern: common
      encoding: UTF-8
      # 是否缓冲输出，使其仅定期刷新
      buffered: true
      # 创建日志文件的目录。可以绝对或相对于Tomcat基础目录（整体一定是绝对路径，windows要加盘符）
      directory: logs
      # 日志文件名前缀
      prefix: ${spring.application.name}-access-
      # 日志文件名后缀
      suffix: .log
      # 要放在日志文件名中的日期格式
      file-date-format: yyyy-MM-dd
      # 日志保留的最大天数，-1表示无限制
      max-days: -1
      # 是否启用访问日志轮换
      rotate: true
      # 是否延迟在文件名中包含日期戳，直到旋转时间
      rename-on-rotate: false
      # 设置请求的IP地址，主机名，协议和端口的请求属性
      request-attributes-enabled: false

spring:
  application:
    name: allen-message-forwarding
  main:
    banner-mode: "off"
  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=500,expireAfterAccess=600s
  datasource:
    # druid相关配置
    druid:
      web-stat-filter:
        enabled: true
        url-pattern: "/*"
        exclusions: "*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*"
        session-stat-enable: true
      stat-view-servlet:
        # 是否启用StatViewServlet默认值true
        enabled: true
        # 访问路径为/druid时，跳转到StatViewServlet
        url-pattern: "/druid/*"
        # 是否能够重置数据
        reset-enable: false
        # 需要账号密码才能访问控制台，默认为root
        login-username: druid
        login-password: druid
        # IP白名单
        allow: 127.0.0.1
        # IP黑名单（共同存在时，deny优先于allow）
        deny:
    dynamic:
      # druid相关配置
      druid:
        # 配置初始化大小/最小/最大
        initial-size: 10
        min-idle: 10
        max-active: 50
        # 获取连接等待超时时间
        max-wait: 60000
        # 间隔多久进行一次检测，检测需要关闭的空闲连接
        time-between-eviction-runs-millis: 60000
        # 一个连接在池中最小生存的时间
        min-evictable-idle-time-millis: 300000
        validation-query: SELECT 'x'
        # 是否在连接空闲一段时间后检测其可用性
        test-while-idle: true
        # 是否在获得连接后检测其可用性
        test-on-borrow: false
        # 是否在连接放回连接池后检测其可用性
        test-on-return: false
        # 打开PSCache，并指定每个连接上PSCache的大小。oracle设为true，mysql设为false。分库分表较多推荐设置为false
        pool-prepared-statements: false
        max-pool-prepared-statement-per-connection-size: 20
        # 监控统计过滤器stat，拦截防注入过滤器wall
        filters: stat,wall
      # 动态数据源的主数据源
      primary: master
      datasource:
        master:
          # 使用druid连接池
          type: com.alibaba.druid.pool.DruidDataSource
          url: jdbc:mysql://localhost:3306/amf?useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&serverTimezone=UTC&allowMultiQueries=true
          # 配置基本属性
          username: root
          password: Root@1234
          driver-class-name: com.mysql.cj.jdbc.Driver
          # druid相关配置
          druid:
            # 配置初始化大小/最小/最大
            initial-size: 5
            min-idle: 5
            max-active: 30
            # 获取连接等待超时时间
            max-wait: 60000
            # 间隔多久进行一次检测，检测需要关闭的空闲连接
            time-between-eviction-runs-millis: 60000
            # 一个连接在池中最小生存的时间
            min-evictable-idle-time-millis: 300000
            validation-query: SELECT 'x'
            # 是否在连接空闲一段时间后检测其可用性
            test-while-idle: true
            # 是否在获得连接后检测其可用性
            test-on-borrow: false
            # 是否在连接放回连接池后检测其可用性
            test-on-return: false
            # 打开PSCache，并指定每个连接上PSCache的大小。oracle设为true，mysql设为false。分库分表较多推荐设置为false
            pool-prepared-statements: false
            max-pool-prepared-statement-per-connection-size: 20
            # 监控统计过滤器stat，拦截防注入过滤器wall
            filters: stat,wall,slf4j
            filter:
              wall:
                enabled: true
                db-type: mysql
                config:
                  # 是否允许同时执行多条语句
                  multi-statement-allow: true
              stat:
                enabled: true
                db-type: mysql
                log-slow-sql: true
                slow-sql-millis: 5000
              slf4j:
                enabled: true
                statement-create-after-log-enabled: false
                statement-close-after-log-enabled: false
                result-set-open-after-log-enabled: false
                result-set-close-after-log-enabled: false
  # redis配置
  redis:
    host: localhost
    port: 6379
    password: redis
    database: 0
    timeout: 1000
    lettuce:
      pool:
        min-idle: 5
        max-idle: 10
        max-active: 10
        max-wait: 5000
  kafka:
    bootstrap-servers:
      - localhost:9092
        #公共参数，其他的timeout.ms, request.timeout.ms, metadata.fetch.timeout.ms保持默认值
        #properties:
        #这个参数指定producer在发送批量消息前等待的时间，当设置此参数后，即便没有达到批量消息的指定大小(batch-size)，到达时间后生产者也会发送批量消息到broker。默认情况下，生产者的发送消息线程只要空闲了就会发送消息，即便只有一条消息。设置这个参数后，发送线程会等待一定的时间，这样可以批量发送消息增加吞吐量，但同时也会增加延迟。
        #linger.ms: 50 #默认值：0毫秒，当消息发送比较频繁时，增加一些延迟可增加吞吐量和性能。
        #这个参数指定producer在一个TCP connection可同时发送多少条消息到broker并且等待broker响应，设置此参数较高的值可以提高吞吐量，但同时也会增加内存消耗。另外，如果设置过高反而会降低吞吐量，因为批量消息效率降低。设置为1，可以保证发送到broker的顺序和调用send方法顺序一致，即便出现失败重试的情况也是如此。
      #注意：当前消息符合at-least-once，自kafka1.0.0以后，为保证消息有序以及exactly once，这个配置可适当调大为5。
      #max.in.flight.requests.per.connection: 1 #默认值：5，设置为1即表示producer在connection上发送一条消息，至少要等到这条消息被broker确认收到才继续发送下一条，因此是有序的。
    producer:
      #这个参数可以是任意字符串，它是broker用来识别消息是来自哪个客户端的。在broker进行打印日志、衡量指标或者配额限制时会用到。
      clientId: ${spring.application.name} #方便kafkaserver打印日志定位请求来源
      #acks=0：生产者把消息发送到broker即认为成功，不等待broker的处理结果。这种方式的吞吐最高，但也是最容易丢失消息的。
      #acks=1：生产者会在该分区的leader写入消息并返回成功后，认为消息发送成功。如果群首写入消息失败，生产者会收到错误响应并进行重试。这种方式能够一定程度避免消息丢失，但如果leader宕机时该消息没有复制到其他副本，那么该消息还是会丢失。另外，如果我们使用同步方式来发送，延迟会比前一种方式大大增加（至少增加一个网络往返时间）；如果使用异步方式，应用感知不到延迟，吞吐量则会受异步正在发送中的数量限制。
      #acks=all：生产者会等待所有副本成功写入该消息，这种方式是最安全的，能够保证消息不丢失，但是延迟也是最大的。
      #如果是发送日志之类的，允许部分丢失，可指定acks=0，如果想不丢失消息，可配置为all，但需密切关注性能和吞吐量。
      acks: all #默认值：1
      #当生产者发送消息收到一个可恢复异常时，会进行重试，这个参数指定了重试的次数。在实际情况中，这个参数需要结合retry.backoff.ms（重试等待间隔）来使用，建议总的重试时间比集群重新选举leader的时间长，这样可以避免生产者过早结束重试导致失败。
      #另外需注意，当开启重试时，若未设置max.in.flight.requests.per.connection=1，则可能出现发往同一个分区的两批消息的顺序出错，比如，第一批发送失败了，第二批成功了，然后第一批重试成功了，此时两者的顺序就颠倒了。
      retries: 2  #发送失败时重试多少次，0=禁用重试（默认值）
      #默认情况下消息是不压缩的，此参数可指定采用何种算法压缩消息，可取值：none,snappy,gzip,lz4。snappy压缩算法由Google研发，这种算法在性能和压缩比取得比较好的平衡；相比之下，gzip消耗更多的CPU资源，但是压缩效果也是最好的。通过使用压缩，我们可以节省网络带宽和Kafka存储成本。
      compressionType: "none" #如果不开启压缩，可设置为none（默认值），比较大的消息可开启。
      #当多条消息发送到一个分区时，Producer会进行批量发送，这个参数指定了批量消息大小的上限（以字节为单位）。当批量消息达到这个大小时，Producer会一起发送到broker；但即使没有达到这个大小，生产者也会有定时机制来发送消息，避免消息延迟过大。
      batch-size: 16384 #默认16K，值越小延迟越低，但是吞吐量和性能会降低。0=禁用批量发送
      #这个参数设置Producer暂存待发送消息的缓冲区内存的大小，如果应用调用send方法的速度大于Producer发送的速度，那么调用会阻塞一定（max.block.ms）时间后抛出异常。
      buffer-memory: 33554432 #缓冲区默认大小32M
    consumer:
      group-id: amf-message-forwarding-consumer
      auto-offset-reset: latest
      #关闭自动提交 改由spring-kafka提交
      enable-auto-commit: false
      #周期性自动提交的间隔，单位毫秒
      auto-commit-interval: 2000 #默认值：5000
      #这个参数允许消费者指定从broker读取消息时最小的Payload的字节数。当消费者从broker读取消息时，如果数据字节数小于这个阈值，broker会等待直到有足够的数据，然后才返回给消费者。对于写入量不高的主题来说，这个参数可以减少broker和消费者的压力，因为减少了往返的时间。而对于有大量消费者的主题来说，则可以明显减轻broker压力。
      fetch-min-size: 1 #默认值： 1
      #上面的fetch.min.bytes参数指定了消费者读取的最小数据量，而这个参数则指定了消费者读取时最长等待时间，从而避免长时间阻塞。这个参数默认为500ms。
      fetch-max-wait: 500 #默认值：500毫秒
      #这个参数控制一个poll()调用返回的记录数，即consumer每次批量拉多少条数据。
      max-poll-records: 500 #默认值：500
    listener:
      #创建多少个consumer，值必须小于等于Kafka Topic的分区数。
      ack-mode: MANUAL_IMMEDIATE
      concurrency: 1  #推荐设置为topic的分区数
  # 支持swagger功能引入
  mvc:
    pathmatch:
      matching-strategy: ANT_PATH_MATCHER
#  cloud:
#    stream:
#      function:
#        definition: demoSave;demoUpdate
#      bindings:
#        demoSave-out-0:
#          destination: demo-save-topic
#          content-type: application/json
#        demoSave-in-0:
#          destination: demo-save-topic
#          content-type: application/json
#          group: demo-save-consumer-group
#        demoUpdate-out-0:
#          destination: demo-update-topic
#          content-type: application/json
#        demoUpdate-in-0:
#          destination: demo-update-topic
#          content-type: application/json
#          group: demo-update-consumer-group
#      rocketmq:
#        binder:
#          name-server: localhost:9876
#          group: allen-demo-group
#        bindings:
#          demoSave-in-0:
#            consumer:
#              enabled: true
#              broadcasting: false
#          demoUpdate-in-0:
#            consumer:
#              enabled: true
#              broadcasting: false
# rocketmq 配置
rocketmq:
  name-server: localhost:9876
  producer:
    group: amf-message-forwarding-producer

# 配置Mybatis Plus
mybatis-plus:
  # xml文件路径
  mapper-locations: classpath*:mapper/**/*Mapper.xml
  # 实体类路径
  type-aliases-package: com.lczq.demo.**.model
  type-handlers-package: com.lczq.**.typehandler
  configuration:
    # 驼峰转换
    map-underscore-to-camel-case: true
    # 是否开启缓存
    cache-enabled: false
    # 打印sql
    # log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  # 全局配置
  global-config:
    # 数据库字段驼峰下划线转换
    db-column-underline: true

# okHttp参数配置
ok:
  http:
    # 连接超时时间，单位：秒
    connect-timeout: 10
    # 读超时时间，单位：秒
    read-timeout: 10
    # 写超时时间，单位：秒
    write-timeout: 10
    # 最大连接数
    max-idle-connections: 200
    # 连接存活时间，单位：秒
    keep-alive-duration: 300

# feign client 参数配置
feign:
  client:
    config:
      default:
        # 设置重试处理器，默认直接抛出异常
        retryer: feign.Retryer.Default
        # 连接超时时间，单位：毫秒
        connect-timeout: 10000
        # 读超时时间，单位：毫秒
        read-timeout: 10000
        # 日志级别
        logger-level: FULL
  okhttp:
    enabled: true
  httpclient:
    enabled: false
  compression:
    request:
      enabled: true
    response:
      enabled: true

# 配置定时任务-示例
xxl:
  job:
    admin:
      addresses: http://localhost:8081/xxl-job-admin
    executor:
      appname: allen-message-forwarding-job-executor
      address:
      ip:
      # 此端口不同项目不能相同
      port: 9090
      logpath: ./logs
      logretentiondays: 30
    accessToken:

# 是否启动swagger
swagger:
  enable: true

allen:
  message:
    forwarding:
      message:
        # 历史消息保留天数
        retention-days: 30
      rocketmq:
        send:
          topic: amf-message-sending
          consumer:
            group: amf-message-sending-consumer
        forward:
          topic: amf-message-forwarding
          consumer:
            group: amf-message-forwarding-consumer
        callback:
          topic: amf-message-callback
          consumer:
            group: amf-message-callback-consumer
      kafka:
        consumer:
          group: amf-message-forwarding-consumer
        send:
          topic: amf-message-sending